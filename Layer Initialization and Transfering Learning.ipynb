{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "993a3075",
   "metadata": {},
   "source": [
    "## Freeze layers of a model\n",
    "- You are about to fine-tune a model on a new task after loading pre-trained weights. The model contains three linear layers. However, because your dataset is small, you only want to train the last linear layer of this model and freeze the first two linear layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac0b822",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "  \n",
    "    # Check for first layer's weight\n",
    "    if name == '0.weight':\n",
    "   \n",
    "        # Freeze this weight\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    # Check for second layer's weight\n",
    "    if name == '1.weight':\n",
    "      \n",
    "        # Freeze this weight\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ca4e4d",
   "metadata": {},
   "source": [
    "## Layer initialization\n",
    "- The initialization of the weights of a neural network has been the focus of researchers for many years. When training a network, the method used to initialize the weights has a direct impact on the final performance of the network.\n",
    "\n",
    "- As a machine learning practitioner, you should be able to experiment with different initialization strategies. In this exercise, you are creating a small neural network made of two layers and you are deciding to initialize each layer's weights with the uniform method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee0af73",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer0 = nn.Linear(16, 32)\n",
    "layer1 = nn.Linear(32, 64)\n",
    "\n",
    "# Use uniform initialization for layer0 and layer1 weights\n",
    "nn.init.uniform_(layer0.weight)\n",
    "nn.init.uniform_(layer1.weight)\n",
    "\n",
    "model = nn.Sequential(layer0, layer1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
