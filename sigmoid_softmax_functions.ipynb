{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ba4e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.tensor([[2.4]])\n",
    "\n",
    "# Create a sigmoid function and apply it on input_tensor\n",
    "sigmoid = nn.Sigmoid()\n",
    "probability = sigmoid(input_tensor)\n",
    "print(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c47b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.tensor([[1.0, -6.0, 2.5, -0.3, 1.2, 0.8]])\n",
    "\n",
    "# Create a softmax function and apply it on input_tensor\n",
    "softmax = nn.Softmax()\n",
    "probabilities = softmax(input_tensor)\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323c068d",
   "metadata": {},
   "source": [
    "## Building a binary classifier in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0669dd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_tensor = torch.Tensor([[3, 4, 6, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Implement a small neural network for binary classification\n",
    "model = nn.Sequential(\n",
    "  nn.Linear(8, 1),\n",
    "  nn.Sigmoid()\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad983d65",
   "metadata": {},
   "source": [
    "## From regression to multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2bbbf4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m      4\u001b[39m input_tensor = torch.Tensor([[\u001b[32m3\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m6\u001b[39m, \u001b[32m7\u001b[39m, \u001b[32m10\u001b[39m, \u001b[32m12\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m6\u001b[39m, \u001b[32m8\u001b[39m, \u001b[32m9\u001b[39m]])\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_tensor = torch.Tensor([[3, 4, 6, 7, 10, 12, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Implement a neural network with exactly four linear layers\n",
    "model = nn.Sequential(\n",
    "  nn.Linear(11, 64),\n",
    "  nn.Linear(64, 32),\n",
    "  nn.Linear(32, 16),\n",
    "  nn.Linear(16, 1),\n",
    "  nn.Softmax(dim=-1)\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffd62bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_tensor = torch.Tensor([[3, 4, 6, 7, 10, 12, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Update network below to perform a multi-class classification with four labels\n",
    "model = nn.Sequential(\n",
    "  nn.Linear(11, 20),\n",
    "  nn.Linear(20, 12),\n",
    "  nn.Linear(12, 6),\n",
    "  nn.Linear(6, 4),\n",
    "  nn.Softmax(dim=-1)\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cb5a0c",
   "metadata": {},
   "source": [
    "### Creating one-hot encoded labels\n",
    "One-hot encoding converts a single integer label into a vector with N elements, where N is the number of classes. This vector contains zeros and a one at the correct position.\n",
    "\n",
    "In this exercise, you'll manually create a one-hot encoded vector for y, and then use PyTorch to simplify the process. Your dataset has three classes (0, 1, 2).\n",
    "\n",
    "\n",
    "Manually one-hot encode the ground truth label y using the provided NumPy array and save it as one_hot_numpy.\n",
    "Use PyTorch to one-hot encode y and save it as one_hot_pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69b5420",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 1\n",
    "num_classes = 3\n",
    "\n",
    "# Create the one-hot encoded vector using NumPy\n",
    "one_hot_numpy = np.array([0,1, 0])\n",
    "\n",
    "# Create the one-hot encoded vector using PyTorch\n",
    "one_hot_pytorch = F.one_hot(torch.tensor(y), num_classes=num_classes)\n",
    "\n",
    "print(\"One-hot vector using NumPy:\", one_hot_numpy)\n",
    "print(\"One-hot vector using PyTorch:\", one_hot_pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de214487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "y = [2]\n",
    "scores = torch.tensor([[0.1, 6.0, -2.0, 3.2]])\n",
    "\n",
    "# Create a one-hot encoded vector of the label y\n",
    "one_hot_label = F.one_hot(torch.tensor(y), num_classes=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2c52c7",
   "metadata": {},
   "source": [
    "#### Calculating cross entropy loss\n",
    "Cross-entropy loss is a widely used method to measure classification loss. In this exercise, youâ€™ll calculate cross-entropy loss in PyTorch using:\n",
    "\n",
    "y: the ground truth label.\n",
    "scores: a vector of predictions before softmax.\n",
    "Loss functions help neural networks learn by measuring prediction errors. Create a one-hot encoded vector for y, define the cross-entropy loss function, and compute the loss using scores and the encoded label. The result will be a single float representing the sample's loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fe2f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "y = [2]\n",
    "scores = torch.tensor([[0.1, 6.0, -2.0, 3.2]])\n",
    "\n",
    "# Create a one-hot encoded vector of the label y\n",
    "one_hot_label = F.one_hot(torch.tensor(y), num_classes=4)\n",
    "\n",
    "# Create the cross entropy loss function\n",
    "criterion = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681298e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "y = [2]\n",
    "scores = torch.tensor([[0.1, 6.0, -2.0, 3.2]])\n",
    "\n",
    "# Create a one-hot encoded vector of the label y\n",
    "one_hot_label = F.one_hot(torch.tensor(y), num_classes=4)\n",
    "\n",
    "# Create the cross entropy loss function\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "# Calculate the cross entropy loss\n",
    "loss = criterion(scores.double(), one_hot_label.double())\n",
    "print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codemode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
